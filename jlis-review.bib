@article{jlis,
abstract = {We present a novel approach for structure pre- diction that addresses the difficulty of obtaining labeled structures for training. We observe that structured output problems often have a compan- ion learning problem of determining whether a given input possesses a good structure. For ex- ample, the companion problem for the part-of- speech (POS) tagging task asks whether a given sequence of words has a corresponding sequence of POS tags that is “legitimate”. While obtaining direct supervision for structures is difficult and expensive, it is often very easy to obtain indirect supervision from the companion binary decision problem. In this paper, we develop a large margin frame- work that jointly learns from both direct and in- direct forms of supervision. Our experiments ex- hibit the significant contribution of the easy-to- get indirect binary supervision on three important NLP structure learning problems.},
author = {Chang, Ming-wei and Srikumar, Vivek and Goldwasser, Dan and Roth, Dan},
isbn = {9781605589077},
journal = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
pages = {199--206},
title = {{Structured Output Learning with Indirect Supervision}},
url = {http://www.icml2010.org/papers/522.pdf},
year = {2010}
}

@article{ssvm,
abstract = {We present a large-margin formulation and algorithm for structured output prediction that allows the use of latent variables. Our proposal covers a large range of applica- tion problems, with an optimization problem that can be solved efficiently using Concave- Convex Programming. The generality and performance of the approach is demonstrated through three applications including motif- finding, noun-phrase coreference resolution, and optimizing precision at k in information retrieval.},
archivePrefix = {arXiv},
arxivId = {1207.4747},
author = {Yu, Cnj and Joachims, Thorsten},
doi = {10.1145/1553374.1553523},
eprint = {1207.4747},
isbn = {9781605585161},
issn = {1605585165},
journal = {{\ldots} International Conference on Machine Learning},
pages = {1--8},
title = {{Learning structural SVMs with latent variables}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553523$\backslash$nhttp://dl.acm.org/citation.cfm?id=1553523},
year = {2009}
}

@article{Chang2009,
abstract = {This paper introduces a novel unsupervised constraint-driven learning algorithm for identifying named-entity (NE) transliterations in bilingual corpora. The proposed method does not require any annotated data or aligned corpora. Instead, it is bootstrapped using a simple resource -- a romanization table. We show that this resource, when used in conjunction with constraints, can efficiently identify transliteration pairs. We evaluate the proposed method on transliterating English NEs to three different languages - Chinese, Russian and Hebrew. Our experiments show that constraint driven learning can significantly outperform existing unsupervised models and achieve competitive results to existing supervised models.},
author = {Chang, Ming-Wei and Goldwasser, Dan and Roth, Dan and Tu, Yuancheng},
doi = {10.3115/1620754.1620798},
isbn = {9781932432411},
issn = {1932432418},
journal = {Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
number = {June},
pages = {299--307},
title = {{Unsupervised constraint driven learning for transliteration discovery}},
url = {http://dl.acm.org/citation.cfm?id=1620798$\backslash$npapers2://publication/uuid/C44DBE19-EF7C-4A42-AF70-01491CFDE7A1},
year = {2009}
}

@inproceedings{contrastive,
abstract = {Conditional random fields (Lafferty et al., 2001) are quite effective at sequence labeling tasks like shallow parsing (Sha and Pereira, 2003) and namedentity extraction (McCallum and Li, 2003). CRFs are log-linear, allowing the incorporation of arbitrary features into the model. To train on unlabeled data, we require unsupervised estimation methods for log-linear models; few exist. We describe a novel approach, contrastive estimation. We show that the new technique can be intuitively understood as exploiting implicit negative evidence and is computationally efficient. Applied to a sequence labeling problem—POS tagging given a tagging dictionary and unlabeled text—contrastive estimation outperforms EM (with the same feature set), is more robust to degradations of the dictionary, and can largely recover by modeling additional features.},
author = {Smith, Noah A. and Eisner, Jason},
booktitle = {ACL'05 - 43rd Annual Meeting of the Association for Computational Linguistics},
doi = {10.3115/1219840.1219884},
isbn = {1932432515},
pages = {354--362},
title = {{Contrastive estimation: Training Log-Linear Models on Unlabeled Data}},
url = {http://www.aclweb.org/anthology/P/P05/P05-1044.pdf},
year = {2005}
}

@article{ccm,
abstract = {Probabilistic modeling has been a dominant approach in Machine Learning research. As the field evolves, thc problems of interest become increasingly challenging and complex. Making complex decisions in real world problems often involves assigning values to sets of interdependent variables where the expressive dependency structure can influence, or even dictate, what assignments are possible. However, incorporating nonlocal depcndencies in a probabilistic model can lead to intractable training and inference. This paper presents Constraints Conditional Models (CCMs), a framework that augments probabilistic models with declarative constraints as a way to support decisions in an expressive output space while maintaining modularity and tractability of training. We further show that declarative constraints can be used to take advantage of unlabeled data when training the probabilistic model.},
author = {Chang, Ming-wei and Ratinov, Lev and Rizzolo, Nicholas and Roth, Dan},
isbn = {978-1-57735-368-3},
journal = {Aaai},
keywords = {Nectar Papers},
pages = {1513--1518},
title = {{Learning and Inference with Constraints}},
year = {2008}
}

@inproceedings{mention-hypergraph,
  title={Joint Mention Extraction and Classification with Mention Hypergraphs},
  author={Lu, Wei and Roth, Dan},
  booktitle={Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP2015)},
  year={2015}
}